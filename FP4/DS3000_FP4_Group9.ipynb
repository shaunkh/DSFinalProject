{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h2> DS 3000 - Fall 2021</h2> </center>\n",
    "<center> <h3> DS Report </h3> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h3>Predicting Start Up Success</h3> </center>\n",
    "<center><h4>Shaun Khundker, Terry Chen, Lauren MacIver</h4></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Executive Summary:\n",
    "\n",
    "The startup ecosystem is quickly adapting and expanding, as the rise of new technology creates new opportunities for business. This trend is suggestive of greater opportunities within the venture capital ecosystem to fund potential successful companies and unlock high profits; however, the subjectiveness of human intuition leaves investors at high risk of loss due to inaccurate perception startup potential. Therefore, we aim to leverage startup data to try and provide a concrete approach to startup success prediction. The data used was originally pulled from Crunchbase, a private and public company information platform and details variables such as funding amounts across funding rounds, location, and industry. Three algorithms were tested for this supervised binary classification problem - kNN, Support Vector Machines, and Decision Trees. K-Nearest Neighbors offered the highest performance and was was hyperparameter tuned to consider 20 neighbors in classification. The final optimized model performance was ~.71 with precision and recall scores of ~.69 and ~.65 respectively, demonstrating opportunity to further refine the model with new feature variables and data in the future to more accurately predict startup success and failure.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "1. <a href='#1'>INTRODUCTION</a>\n",
    "2. <a href='#2'>METHOD</a>\n",
    "3. <a href='#3'>RESULTS</a>\n",
    "4. <a href='#4'>DISCUSSION</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<h4>Problem Statement</h4>\n",
    "\n",
    "Investors aim to identify unicorn companies with high valuations among a large pool of investment options. Venture capitalism has historically been focused on sourcing relationships with founders, conducting due diligence, and often basing investment decisions on intuition and experience rather than data. With the increased availability of start up information, we aim to develop a concrete model to support investors in determining the likelihood of start up success. We hope to gain a greater understanding of the key considerations of due diligence and how to best leverage these data points to create an accurate predictive model. \n",
    "\n",
    "<h4>Significance of the Problem</h4>\n",
    "\n",
    "Historically, failure is a costly but effective way to train a venture capitalist. With increased access to data surrounding early stage companies, leveraging machine learning models in venture capital is a powerful mechanism to supplement an intuition based industry. The insights from this project would allow for an increased rate of identification of potential unicorn companies that ultimately improve product offerings to consumers. When coupled with proper data and human intuition, machine learning models in venture capital can challenge biases and improve  accuracy in predicting start-up potential. Many firms are already shifting to a data driven approach and have seen successful returns in response. However, the majority of firms utilize these datasets as search engines to locate potential deals leaving a demand for machine learning models that identify key indicators of potential unicorn companies in early stage investments. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<h4>Questions</h4>\n",
    "\n",
    "Given the aforementioned problem and its importance, we set out to tackle the following questions: \n",
    "\n",
    "* Can we predict whether a startup suceeds (is acquired) or fails (closes down) based on some characteristics of the startup?\n",
    "* Is k-Nearest Neighbors better than Support Vector Machines and Decision Trees in predicting start up success based on performance accuracy?\n",
    "* Which features most greatly influence the outcome variable? Are there a subset of features that are strongly correlated to the target?\n",
    "* Will feature selection improve overall model performance?\n",
    "\n",
    "<h4>Hypotheses</h4>\n",
    "\n",
    "Null: The success of a startup and its funding features have no relationship (H1,0). \n",
    "\n",
    "Alternative: The success of a startup and its funding features have a relationship (H1,1). \n",
    "\n",
    "Null: The success of a startup and the market that it is in have no relationship (H2, 0). \n",
    "\n",
    "Alternative: The success of a startup and the market that it is in have a relationship (H2, 1). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. METHOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Data Acquisition\n",
    "The dataset was obtained using [Kaggle](https://www.kaggle.com/arindam235/startup-investments-crunchbase) and contains information intially pulled from Crunchbase, an information platform for public and private company data. The dataset contains 54294 samples of startups and 30 variables as described below. Status is the outcome variable.\n",
    "\n",
    "| **Variable** | **Description** |  \n",
    "\n",
    "| --- | --- | --- |\n",
    "\n",
    "| name | name of startup |\n",
    "\n",
    "| market | industry of startup |\n",
    "\n",
    "| funding_total | total funding raised by startup in USD |\n",
    "\n",
    "| state_code | the state in which the startup is located |\n",
    "\n",
    "| funding_rounds | number of funding rounds |\n",
    "\n",
    "| founded_at | date (year/month/date) the startup was founded|\n",
    "\n",
    "| first_funding_at | date (year/month/date) the startup got its first funding |\n",
    "\n",
    "| last_funding_at | date (year/month/date) the startup got its last funding |\n",
    "\n",
    "| seed | funding raised during seed round in USD |\n",
    "\n",
    "| venture | total venture funding amount |\n",
    "\n",
    "| undisclosed | undisclosed funding in USD |\n",
    "\n",
    "| convertible_note | funding raised using convertible notes in USD |\n",
    "\n",
    "| debt_financing | total debt financing amount in USD |\n",
    "\n",
    "| angel | funding raised by angles in USD |\n",
    "\n",
    "| grant | funding raised through grants in USD |\n",
    "\n",
    "| private_equity | funding raised by private equity in USD |\n",
    "\n",
    "| post_ipo_equity |amount of funding raised after going public in USD|\n",
    "\n",
    "| post_ipo_debt |amount of debt financing after going public in USD |\n",
    "\n",
    "| secondary_market |amount of funding raised through secondary market in USD |\n",
    "\n",
    "| product_crowdfunding |amount of funding raised through product crowdfunding in USD|\n",
    "\n",
    "| round A |amount of funding raised from round A in USD |\n",
    "\n",
    "| round B |amount of funding raised from round B in USD |\n",
    "\n",
    "| round C |amount of funding raised from round C in USD |\n",
    "\n",
    "| round D |amount of funding raised from round D in USD |\n",
    "\n",
    "| round E |amount of funding raised from round E in USD |\n",
    "\n",
    "| round F |amount of funding raised from round F in USD |\n",
    "\n",
    "| round G |amount of funding raised from round G in USD |\n",
    "\n",
    "| round H |amount of funding raised from round H in USD |\n",
    "\n",
    "| *status* | *whether the startup is acquired or closed* |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Data Analysis\n",
    "\n",
    "\n",
    "As mentioned above, this project aims to predict start up status (closed or acquired), the outcome variable. The remaining 29 feature variables are important predictors as they provide additional information on aspects that can play a significant role in a startup's ability to succeed such as funding totals and different funding rounds, market, and state of origin. \n",
    "\n",
    "This is a supervised machine learning problem as we will be developing a predictive model based on both input data (labeled start up feature variables) and output data (start up status). Our project is tackling a classification problem because we are predicting which startups will succeed given a set of labeled feature variables like the amount of funding raised. Our target label, whether the startups succeed or not, is binary and categorical and therefore a classification problem. \n",
    "\n",
    "We are planning to try k-Nearest Neighbors, Linear SVC and Decision Trees. We choose these three algorithms as they are classification algorithms covered in class that suit the needs of our project. We chose not to use Naive Bayes because we were not confident that each of the features are equally important. In the model training section of this report, we test all these aforementioned algorithms to determine which will perform best as we prior to training we have no reason to believe one will be better than another. The K-Nearest Neighbors algorithm is one of the simplest machine learning models and has very few hyperparamters to tune(K value and distance function). The algorithm relies on the underlying assumption that items in close proximity to one another are similar and leverages distance to classify new samples. Linear Support Vector Classification attempts to draw a hyperplane in which the support vector margins are as large as possible. The support vectors are the most useful data points because they are the ones most likely to be incorrectly classified. Part of the reasoning behind including SVM was because it can handle outliers better than most other models. On the other hand, decision trees are rule based classifiers that assume that initially, at the root, all the training data is examined. The data is continually split until all data points are isolated to a class. We included decision trees as one of our models because it is highly effective in handling colinearity which is a possibility we wanted to be mindful of in our dataset. We are going to try all these because we do not have reason to think that one is better than the other; however, we have chosen to omit the Naive Bayes algorithm because features are not all equally important. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Data Wrangling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-557c294884db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://raw.githubusercontent.com/shaunkh/DSFinalProject/main/investments_VC.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'unicode_escape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[0;31m# open URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m     ioargs = _get_filepath_or_buffer(\n\u001b[0m\u001b[1;32m    559\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0;34m\"storage_options passed with file object or non-fsspec file path\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             )\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content-Encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    641\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/shaunkh/DSFinalProject/main/investments_VC.csv?token=AWG2IGQOBKUDSCUJAYKYD4TBXQEEC\", encoding= 'unicode_escape')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Data Cleaning\n",
    "In this section we remove unnecessary columns to that will not contribute to model accuracy, dropna samples, and rename columns for simplicity. These modifications will ensure that there are relevant values for each of our feature variables that can be used in training and testing the model. The scope of this project is only startups within the United States. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data, drop NA values for our target variable\n",
    "df = df.dropna(subset=['status'], axis = 0)\n",
    "\n",
    "# Drop unecessary columns\n",
    "df = df.drop(['permalink', 'homepage_url', 'category_list', 'founded_month', 'founded_quarter','founded_year',\n",
    "             'founded_at', 'first_funding_at', 'last_funding_at'], axis = 1)\n",
    "\n",
    "# Limit data to only USA\n",
    "df = df[df[\"country_code\"] == \"USA\"]\n",
    "\n",
    "# Keep only rows that are 'acquired' or 'closed'\n",
    "df = df[df[\"status\"] != \"operating\"]\n",
    "\n",
    "# Rename columns for ease of use\n",
    "df = df.rename({' market ': 'market', ' funding_total_usd ': 'funding_total_usd'}, axis=1)\n",
    "\n",
    "# can we move this to the data cleaning section?\n",
    "df = df.drop([\"country_code\", \"region\", \"city\"], axis=1)\n",
    "df = df.dropna(subset=['state_code'], axis = 0)\n",
    "df = df.dropna(subset=['market'], axis = 0)\n",
    "\n",
    "df = df.astype({'market': 'str', 'name': 'str', 'status': 'str', 'state_code': 'str'})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 Dataframe Formatting\n",
    "Non-numeric values are converted into integers. Since funding values are initally stored as strings with commas we must strip additional space and remove the commas by appling the defined function below so that these values can be converted into integers and later used in the model. Additionally, the target variable Status, is converted to 1 (acquired) or 0 (closed). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatFunding(x):\n",
    "    val = x.strip()\n",
    "    val = val.replace(\",\", \"\")\n",
    "    return val\n",
    "\n",
    "# Format to numbers\n",
    "df[\"funding_total_usd\"] = df[\"funding_total_usd\"].apply(lambda x: formatFunding(x))\n",
    "df = df[df[\"funding_total_usd\"] != \"-\"]\n",
    "df = df.astype({'funding_total_usd': 'int64'})\n",
    "\n",
    "df[[\"market\", \"name\", \"status\", \"state_code\"]] = df[[\"market\", \"name\", \"status\", \"state_code\"]].apply(lambda x: x.str.strip())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the original dataframe to preseve associations of the categorical label, Status\n",
    "df_n = df.copy(deep=True)\n",
    "df_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert status values to 0 (closed) and 1 (acquired) \n",
    "df[\"status\"] = df[\"status\"].apply(lambda x: 1 if (x == \"acquired\") else 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.4 Feature Extraction: One-Hot-Encoding\n",
    "We leverage One-Hot Encoding to convert categorical variables into new features with 0 or 1 values so that they can be used in the model. One-Hot Encoding converts categorical variables into categorical columns using 0 and 1 values to signify whether sample meets the categorical criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab non-numeric features that must be one-hot encoded\n",
    "features = df.iloc[:, 1:5]\n",
    "features = features.drop([\"funding_total_usd\", \"status\"], axis=1)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe to hold all the complete dataset including one hot encoded variables. \n",
    "temp = df.copy(deep=True)\n",
    "temp = pd.get_dummies(temp, columns=[\"market\", \"state_code\"], prefix=[\"market\", \"state_code\"])\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature and target dataframes, removing the target variable from the feature df\n",
    "features = temp.drop([\"name\", \"status\"], axis = 1)\n",
    "target = df[\"status\"]\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.5 Preprocessing: MinMaxScaler\n",
    "We leverage MinMaxScaler to transform features by scaling each feature to a given range. This ensures that features on different scales do not contribute unevenly to the model and in turn create a potential bias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# preprocess using MinMaxScaler\n",
    "def preprocessor(train, test):\n",
    "    scaler = MinMaxScaler().fit(train)\n",
    "    \n",
    "    #scale testing and training sets\n",
    "    X_train_scaled = scaler.transform(train)\n",
    "    X_test_scaled = scaler.transform(test)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing sets\n",
    "def split_train_test(features, target):\n",
    "    splits = train_test_split(features, target, random_state=3000)\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training and testing sets\n",
    "X_train, X_test, y_train, y_test = split_train_test(features, target)\n",
    "\n",
    "# process features\n",
    "X_train_scaled, X_test_scaled = preprocessor(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.6 Dimensionality Reduction with TSNE\n",
    "We use dimensionality reduction in attempts to represent 30 features in two simple components. Dimesionality reduction is beneficial in this project as it helps boil down the high dimesionality dataset and improve computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, random_state=3000)\n",
    "\n",
    "reduced_data = tsne.fit_transform(X_train_scaled)\n",
    "\n",
    "reduced_df = pd.DataFrame(reduced_data, columns = [\"Component1\", \"Component2\"])\n",
    "reduced_df[\"target\"] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "graph = px.scatter(reduced_df, x=\"Component1\", y=\"Component2\", color = \"target\")\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Data Exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Top 20 Markets by Funding \n",
    "Total funding amount is very important because that seems to play a role in how successful the startup is, and markets also seem to play a part as it could be easier to succeed in one market than another due to the nature of a given market. Therefore, we wanted to visualize the top (most frequent) markets on the x-axis and their corresponding total funding amounts on the y-axis to see if there is a relationship between market type and funding amount. The figure below illustrates that the highest total funding is generally related to technology (i.e. software, biotechnology, clean technology, internet, and mobile). We also see that startups in the majority of these industries have a greater rate of success than failure (acquired > closed) besides the manufacturing industry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "markets = df.groupby(\"market\")\n",
    "\n",
    "marketsbyfunding = markets[\"funding_total_usd\"].sum().sort_values(ascending = False).head(20)\n",
    "\n",
    "fig = px.bar(marketsbyfunding,\n",
    "            labels = {\n",
    "                \"value\": \"Total Funding\",\n",
    "                \"market\": \"Market\"\n",
    "            },\n",
    "            title = \"Top 10 Markets by Funding Amount\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ibb.co/LpjRqpF/newplot-8.png\" alt=\"newplot-8\" width =700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Debt Financing to Total Funding \n",
    "Understanding the type of financing a startup receives is also important in considering whether a startup will succeed because it’s a different way of funding compared to venture capital. Therefore we visualize debt financing on the x-axis and total funding amount on the y-axis to get an understanding of how much each startups total funding is made up of debt and if there is any correlation between these two and overall startup success. Note that an outlier of $5.7B was removed for better visualization. The scatter below suggests that startups with higher proportions of debt financing to total funding have a higher frequency of success. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_outliers = df_n[df_n.funding_total_usd != 5700000000]\n",
    "fig = px.scatter(df_no_outliers, x=\"debt_financing\", y=\"funding_total_usd\", color=\"status\", title = \"Debt Financing to Total Funding\")\n",
    "fig.update_layout(title_x = 0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ibb.co/DMwZB9P/newplot-3.png\" alt=\"newplot-3\" width=1000>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Matrix of Early Stage Funding\n",
    "Start up funding occurs through a series of rounds, and often the successful early stage funding can indicate a startups overall ability to capture new opportunities and grow. We visualize a matrix of the early stage funding rounds to better understand how companies react to successful or unsuccessful funding rounds, and how that attributes to over all success. \n",
    "The figure below shows that startups with lower series A funding tend to have higher series C funding. The same is true for companies that experience low series B funding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_funding = df_n[['round_A', 'round_B','round_C']]\n",
    "fig = px.scatter_matrix(df_n, dimensions = early_funding, color = \"status\", template ='ggplot2', title = \"Matrix of Early Stage Funding\",\n",
    "                       labels={col:col.replace('_', ' ') for col in df.columns}, width = 400, height = 400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ibb.co/1vyCS1d/newplot-6.png\" alt=\"newplot-6\" width = 400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4 Venture Funding vs Total Funding\n",
    "Funding raised from venture capital is known to be one of largest portions of total startup funding. We visualize this with venture funding on the x-axis and total funding on the y-axis to further understand how these two features play into startup success. The figure below demonstrates a positve correlation between venture funding and start up funding and indicates that startups with higher quantities of venture funding tend to succeed over startups with relatively small venture funding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outlier total funding values\n",
    "values = [5700000000, 466000000, 925000000]\n",
    "\n",
    "#drop rows that contain any value in the outliers list, we do this here only for visualization purposes\n",
    "df_no_outliers = df_n[df_n.funding_total_usd.isin(values) == False]\n",
    "df_no_outliers = df_no_outliers[df_no_outliers.venture != 660200000]\n",
    "\n",
    "fig = px.scatter(df_no_outliers, x = 'venture', y ='funding_total_usd', color = 'status', title = 'Venture Funding vs Total Funding',\n",
    "                 labels = {\"funding_total_usd\" : \"Total Funding\", \"venture\" : \"Venture Funding\"})\n",
    "fig.update_layout(title_x = 0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ibb.co/YBGbWws/newplot-7.png\" alt=\"newplot-7\" width= 700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Model Training\n",
    "**TODO: For your machine learning question(s), use the Training, Validation, and Testing approach through GridSearch**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 RFE Feature Selection\n",
    "\n",
    "We chose to use run RFE feature selection as not all features are likely to matter; we found that 15 features worked best. After running tests, a smaller feature set worked better than the original amount. We compare the performance of the algorithms using the selected and all features below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8e7e0e7825ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# get selected features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mX_train_selected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_selected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFE_Selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "# function for codnucting RFE feature selection\n",
    "def RFE_Selection(features, x_train, x_test, ytrain):\n",
    "    feature_selection = RFE(DecisionTreeRegressor(random_state = 3000), n_features_to_select = 15)\n",
    "\n",
    "    feature_selection.fit(X_train_scaled, ytrain)\n",
    "\n",
    "    X_train_selected = feature_selection.transform(X_train_scaled)\n",
    "    X_test_selected = feature_selection.transform(X_test_scaled)\n",
    "    \n",
    "    selected_features = [feature for feature, status in zip(features, feature_selection.get_support()) if status == True]\n",
    "    print('Selected startup features:')\n",
    "    for feature in selected_features:\n",
    "        print('\\t' + feature)\n",
    "\n",
    "    return X_train_selected, X_test_selected, selected_features\n",
    "\n",
    "# get selected features\n",
    "X_train_selected, X_test_selected, selected_features = RFE_Selection(features, X_train_scaled, X_test_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Model training using RFE selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "estimators = {\n",
    "    'k-Nearest Neighbor': KNeighborsClassifier(), \n",
    "    'Support Vector Machine': LinearSVC(max_iter=1000000),\n",
    "    'Decision Tree': DecisionTreeClassifier()}\n",
    "\n",
    "# with selected features\n",
    "for estimator, estimator_object in estimators.items():\n",
    "    #fit scaled sets to model\n",
    "    model = estimator_object.fit(X=X_train_selected, y=y_train)\n",
    "\n",
    "    print(estimator + \":\")\n",
    "    #prediction accuracy\n",
    "    accuracy = model.score(X_train_selected, y_train)\n",
    "    print(\"Prediction accuracy on the training data:\", format(accuracy*100, \".2f\"))\n",
    "    accuracy = model.score(X_test_selected, y_test)\n",
    "    print(\"Prediction accuracy on the test data:\", format(accuracy*100, \".2f\"), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.3 Model training without RFE selection\n",
    "We note an improvement in model performance across all three algorithms when using RFE. This suggests that a smaller subset of our features is more representative of our outcome variable than all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with scaled features but not selected\n",
    "for estimator, estimator_object in estimators.items():\n",
    "    #fit scaled sets to model\n",
    "    model = estimator_object.fit(X=X_train_scaled, y=y_train)\n",
    "    \n",
    "    print(estimator + \":\")\n",
    "    #prediction accuracy\n",
    "    accuracy = model.score(X_train_scaled, y_train)\n",
    "    print(\"Prediction accuracy on the training data:\", format(accuracy*100, \".2f\"))\n",
    "    accuracy = model.score(X_test_scaled, y_test)\n",
    "    print(\"Prediction accuracy on the test data:\", format(accuracy*100, \".2f\"), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.5 Overfitting vs Underfitting\n",
    "Looking at the performance of the model above there is indication of overfitting. Regardless of the algorithm used, the model has high variance between the training and testing set performance, and high bias as indicated by relatively low training and validation scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.6 Model performance with evaluation metrics\n",
    "After looking at the prediction accuracy above, we conclude that kNN is the best algorithm to use in this scenario as it has the highest score on the test set and a relatively small difference between training and test data. Similarly, looking at the classifcation metrics below we see that kNN has the highest overall prediction, recall, and f1 score. The model has a greater recall than precision when predicting successful start ups, meaning the rate it correctly predicts successful startups out of all true successful startups is greater than the rate it correctly predicts successful startups out of correctly predicting both success and failure.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "for estimator, estimator_object in estimators.items():\n",
    "    model = estimator_object.fit(X=X_train_selected, y=y_train)\n",
    "    #make predictions on the test set\n",
    "    predicted = model.predict(X=X_test_selected)\n",
    "\n",
    "    expected = y_test\n",
    "    \n",
    "    class_report = classification_report(y_true=expected, y_pred=predicted)\n",
    "    print(estimator, \":\")\n",
    "    print(class_report, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** GridSearch was done below in Model Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Model Optimization\n",
    "Below we leverage Grid Search to determine the most optimal parameters for kNN. The hyperparameter to be tuned in kNN is the number of neighbors. It is important to conduct hyperparameter tuning to ensure that our model is not overfit and too complex. Overfitting diminishes overall generalizability, hurting the models ability to give accurate predictions on new, unseen data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = dict(n_neighbors=[1, 5, 10, 20, 50])\n",
    "\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "# fit the grid search object on the training data (CV will be performed on this)\n",
    "grid_search.fit(X=X_train_selected, y=y_train)\n",
    "\n",
    "# this is the best performance during training\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "# result of grid search\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "print(\"Training set score with best parameters: \", grid_search.score(X_train_selected, y_train))\n",
    "\n",
    "# the performance of the best found parameters on the test set\n",
    "print(\"Test set score with best parameters: \", grid_search.score(X_test_selected, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 20)\n",
    "model = knn.fit(X=X_train_selected, y=y_train)\n",
    "\n",
    "predicted = model.predict(X=X_test_selected)\n",
    "expected = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model.score(X_test_selected, y_test)\n",
    "print(\"Final accuracy on testing set:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e5afedefb882>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclass_report\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_report\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "class_report = classification_report(y_true=expected, y_pred=predicted)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6919965620102129\n",
      "Recall: 0.6550949560955688\n",
      "F1-Score: 0.6614819759679573\n",
      "Support: 922 \n",
      "\n",
      "Final accuracy on testing set: 0.7136659436008677\n"
     ]
    }
   ],
   "source": [
    "# summary of testing\n",
    "class_report = classification_report(y_true=expected, y_pred=predicted, output_dict=True)\n",
    "print(\"Precision:\", class_report['macro avg']['precision'])\n",
    "print(\"Recall:\", class_report['macro avg']['recall'])\n",
    "print(\"F1-Score:\", class_report['macro avg']['f1-score'])\n",
    "print(\"Support:\", class_report['macro avg']['support'], \"\\n\")\n",
    "\n",
    "print(\"Final accuracy on testing set:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DISCUSSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Findings\n",
    "We compared three algorithms:\n",
    "1. kNN\n",
    "2. Linear SVC\n",
    "3. Decision Tree\n",
    "\n",
    "Of the three algorithms, the kNN algorithm had the best performance with a performance of  with the hyperparameter, n_neighbors, optimized to 20 based on the GridSearch. Therefore kNN (n_neighbors = 20) should be used for the predictive model. Based on our findings, the features we used to predict our outcome variable should not be used on their own given the model performance is still relatively low ~.713. Similarly, the precision and recall scores, and in turn the F1 score, have room for improvement to bring them closer to one and improve the models overall ability to correctly predict our target outcome. Support is simply the indication of actual occurrences in the training set and will not change between models. \n",
    "\n",
    "**NOTE: Interpretation of findings 3.3 and 3.4 were also detailed under each respective section.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Ethical Implications\n",
    "The results of this model should not be taken at face value. For example, in the RFE model, we may notice location bias, as only certain locations were selected. Therefore, as we apply our model to new, unseen data from across the US, we may see a greater false positive rate for startups from the selected states. Similarly, the vast amounts of industries across the startup ecosystem are not represented in our current dataset. Introducing this model to new data may reveal higher false positive rates for startups in the tech space, the most frequently occurring industry in our dataset. The potential biases in this model have great implications. Specifically, if using this model from an investor standpoint, these biases may deter investors from providing capital to startups which actually have the means to succeed. While this concern is not as grave as other potential ML ethical implications, it is certainly an important consideration. Finally, the dataset used to train this model is dated relative to the quickly evolving nature of the startup ecosystem. This means that the model is trained on data that is not truly representative of the population and thus has a limited ability to provide accurate predictions. Overall, the model can be useful in identifying potential trends, but shouldn't be used to indicate which ventures to invest in. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Future Work\n",
    "Looking forward, there remain many opportunities to improve this project. First, more data and features need to be gathered. Specifically, global data and other key variables such as the number of employees, founder background, management team, market size, market potential, etc).  Increasing the data and features used will help us determine which features are most representative of the outcome variable, hopefully improving the performance from what it is as we complete this report. Next, other algorithms/analysis can be tested such as Logistic Regression and Random Forest, and even Neural Networks to see if the model performance improves using an alternative approach. Finally, the approach to this project could change entirely to or used in tamdem with text classification to predict start up success through scraping data from social media platform such as Twitter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONTRIBUTIONS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial data cleaning and and data wrangling portions upto section 3.1 were done as a group via zoom screen share. After the data had been cleaned and wrangled, Shaun completed the remainder of the model training and testing. Terry completed the visualizations and write up sections of the report. Lauren was reponsible for editing of the completed report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
